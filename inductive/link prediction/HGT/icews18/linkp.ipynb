{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d50819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(\n",
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import Linear, ReLU\n",
    "from torch_geometric.nn import HGTConv\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = 'icews18'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd9e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGTEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels_dict, hidden_channels, out_channels, metadata, num_heads=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = HGTConv(in_channels_dict, hidden_channels, metadata, heads=num_heads)\n",
    "        self.conv2 = HGTConv({k: hidden_channels for k in in_channels_dict}, out_channels, metadata, heads=num_heads)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {k: F.relu(v) for k, v in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a03b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        return torch.sigmoid(self.mlp(x_i * x_j)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e257bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, predictor, data, edge_type):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    z_dict = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    pos_edge_index = data[edge_type].edge_label_index\n",
    "    # neg_edge_index = data[edge_type].neg_edge_label_index\n",
    "    \n",
    "\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data[edge_type].edge_index,\n",
    "        num_nodes=data[edge_type[0]].num_nodes,\n",
    "        num_neg_samples=data[edge_type].edge_label_index.size(1),\n",
    "        method='sparse'\n",
    "    )\n",
    "\n",
    "    src_pos, dst_pos = pos_edge_index\n",
    "    src_neg, dst_neg = neg_edge_index\n",
    "\n",
    "    pos_pred = predictor(z_dict[edge_type[0]][src_pos], z_dict[edge_type[2]][dst_pos])\n",
    "    neg_pred = predictor(z_dict[edge_type[0]][src_neg], z_dict[edge_type[2]][dst_neg])\n",
    "\n",
    "    pred = torch.cat([pos_pred, neg_pred]).cpu()\n",
    "    label = torch.cat([torch.ones_like(pos_pred), torch.zeros_like(neg_pred)]).cpu()\n",
    "\n",
    "    auc = roc_auc_score(label, pred)\n",
    "    ap = average_precision_score(label, pred)\n",
    "    return auc, ap\n",
    "\n",
    "\n",
    "def train(model, predictor, data, optimizer, edge_type):\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    z_dict = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    pos_edge_index = data[edge_type].edge_label_index\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=pos_edge_index,\n",
    "        num_nodes=data[edge_type[0]].num_nodes,\n",
    "        num_neg_samples=pos_edge_index.size(1)\n",
    "    )\n",
    "\n",
    "    src_pos, dst_pos = pos_edge_index\n",
    "    src_neg, dst_neg = neg_edge_index\n",
    "\n",
    "    pos_pred = predictor(z_dict[edge_type[0]][src_pos], z_dict[edge_type[2]][dst_pos])\n",
    "    neg_pred = predictor(z_dict[edge_type[0]][src_neg], z_dict[edge_type[2]][dst_neg])\n",
    "\n",
    "    pred = torch.cat([pos_pred, neg_pred])\n",
    "    label = torch.cat([torch.ones_like(pos_pred), torch.zeros_like(neg_pred)])\n",
    "\n",
    "    loss = F.binary_cross_entropy(pred, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6484636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_example():\n",
    "#     # Build a toy hetero graph\n",
    "#     data = HeteroData()\n",
    "#     data['user'].x = torch.randn(100, 32)\n",
    "#     data['item'].x = torch.randn(200, 32)\n",
    "\n",
    "#     edge_index = torch.randint(0, 100, (2, 500))  # 500 user-item links\n",
    "#     data['user', 'rates', 'item'].edge_index = edge_index\n",
    "\n",
    "#     # Make it undirected and split\n",
    "#     transform = ToUndirected()  # optional, depends on the task\n",
    "#     data = transform(data)\n",
    "#     split = RandomLinkSplit(\n",
    "#         edge_types=[('user', 'rates', 'item')],\n",
    "#         rev_edge_types=[('item', 'rev_rates', 'user')],\n",
    "#         add_negative_train_samples=True\n",
    "#     )\n",
    "#     train_data, val_data, test_data = split(data)\n",
    "\n",
    "#     metadata = train_data.metadata()\n",
    "#     in_channels_dict = {k: v.size(-1) for k, v in train_data.x_dict.items()}\n",
    "\n",
    "#     # Model\n",
    "#     encoder = HGTEncoder(in_channels_dict, hidden_channels=64, out_channels=64, metadata=metadata).to('cpu')\n",
    "#     predictor = LinkPredictor(in_dim=64).to('cpu')\n",
    "#     optimizer = torch.optim.Adam(list(encoder.parameters()) + list(predictor.parameters()), lr=0.005)\n",
    "\n",
    "#     # Training loop\n",
    "#     edge_type = ('user', 'rates', 'item')\n",
    "#     for epoch in range(1, 51):\n",
    "#         loss = train(encoder, predictor, train_data, optimizer, edge_type)\n",
    "#         if epoch % 10 == 0:\n",
    "#             val_auc, val_ap = evaluate(encoder, predictor, val_data, edge_type)\n",
    "#             print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Val AUC: {val_auc:.4f}, AP: {val_ap:.4f}\")\n",
    "\n",
    "#     test_auc, test_ap = evaluate(encoder, predictor, test_data, edge_type)\n",
    "#     print(f\"Test AUC: {test_auc:.4f}, Test AP: {test_ap:.4f}\")\n",
    "\n",
    "# run_example()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a176dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist = pd.read_csv(f'../../../../data/raw/{dataset}/1-indexed/actor_actor.csv', encoding='utf-8', names=['userID','artistID', 'weight'],)\n",
    "user_friend = pd.read_csv(f'../../../../data/raw/{dataset}/1-indexed/actor_action.csv', encoding='utf-8', names=['userID', 'friendID'])\n",
    "user_tag = pd.read_csv(f'../../../../data/raw/{dataset}/1-indexed/actor_sector.csv', encoding='utf-8', names=['artistID', 'tagID'])\n",
    "\n",
    "# indices = np.arange(len(user_artist))\n",
    "# train_idx, test_idx = train_test_split(indices, test_size=0.15, random_state=42)\n",
    "# val_idx, test_idx = train_test_split(test_idx, test_size=0.5, random_state=42)\n",
    "# train_data, val_data, test_data = create_data(user_artist, train_idx, val_idx, test_idx)\n",
    "\n",
    "num_actor1 = user_artist['userID'].max()+1\n",
    "num_actor2 = user_artist['artistID'].max()+2\n",
    "num_action = user_friend['friendID'].max()+1\n",
    "num_sector = user_tag['tagID'].max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9deda3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73510"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_friend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e181fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "data['actor1'].x = torch.randn(num_actor1, 32)\n",
    "data['actor2'].x = torch.randn(num_actor2, 32)\n",
    "data['action'].x = torch.randn(num_action, 32)\n",
    "data['sector'].x = torch.randn(num_sector, 32)\n",
    "\n",
    "edge_index = torch.tensor(user_artist[[user_artist.columns[0], user_artist.columns[1]]].values.T, dtype=torch.long)\n",
    "\n",
    "data['actor1', 'interacts', 'actor2'].edge_index = torch.tensor(user_artist[[user_artist.columns[0], user_artist.columns[1]]].values.T, dtype=torch.long)\n",
    "data['actor1', 'involved', 'action'].edge_index = torch.tensor(user_friend[[user_friend.columns[0], user_friend.columns[1]]].values.T, dtype=torch.long)\n",
    "data['actor1', 'belongs', 'sector'].edge_index = torch.tensor(user_tag[[user_tag.columns[0], user_tag.columns[1]]].values.T, dtype=torch.long)\n",
    "\n",
    "transform = ToUndirected()  # optional, depends on the task\n",
    "data = transform(data)\n",
    "\n",
    "split = RandomLinkSplit(\n",
    "    edge_types=[('actor1', 'interacts', 'actor2'),('actor1', 'involved', 'action'),('actor1', 'belongs', 'sector')],\n",
    "    rev_edge_types=[('actor2', 'rev_interacts', 'actor1'),('action', 'rev_involved', 'actor1'),('sector', 'rev_belongs', 'actor1')],\n",
    "    add_negative_train_samples=True\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = split(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05fa89db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ∩ Val: 2848\n",
      "Train ∩ Test: 4634\n",
      "Val ∩ Test: 1704\n"
     ]
    }
   ],
   "source": [
    "def edge_set(data, etype):\n",
    "    return set(map(tuple, data[etype].edge_label_index.t().tolist()))\n",
    "\n",
    "etype = ('actor1', 'interacts', 'actor2')\n",
    "train_edges = edge_set(train_data, etype)\n",
    "val_edges = edge_set(val_data, etype)\n",
    "test_edges = edge_set(test_data, etype)\n",
    "\n",
    "print(\"Train ∩ Val:\", len(train_edges & val_edges))\n",
    "print(\"Train ∩ Test:\", len(train_edges & test_edges))\n",
    "print(\"Val ∩ Test:\", len(val_edges & test_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "968ad006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test():\n",
    "    metadata = train_data.metadata()\n",
    "    in_channels_dict = {k: v.size(-1) for k, v in train_data.x_dict.items()}\n",
    "\n",
    "    # Model\n",
    "    encoder = HGTEncoder(in_channels_dict, hidden_channels=64, out_channels=64, metadata=metadata).to('cpu')\n",
    "    predictor = LinkPredictor(in_dim=64).to('cpu')\n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(predictor.parameters()), lr=0.005)\n",
    "\n",
    "    # Training loop\n",
    "    edge_type = ('actor1', 'interacts', 'actor2')\n",
    "    for epoch in range(1, 51):\n",
    "        loss = train(encoder, predictor, train_data, optimizer, edge_type)\n",
    "        if epoch % 10 == 0:\n",
    "            val_auc, val_ap = evaluate(encoder, predictor, val_data, edge_type)\n",
    "            print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Val AUC: {val_auc:.4f}, AP: {val_ap:.4f}\")\n",
    "\n",
    "    test_auc, test_ap = evaluate(encoder, predictor, test_data, edge_type)\n",
    "    print(f\"Test AUC: {test_auc:.4f}, Test AP: {test_ap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4292817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010, Loss: 0.6691, Val AUC: 0.6216, AP: 0.6427\n",
      "Epoch 020, Loss: 0.6104, Val AUC: 0.6842, AP: 0.7378\n",
      "Epoch 030, Loss: 0.5806, Val AUC: 0.6962, AP: 0.7583\n",
      "Epoch 040, Loss: 0.5684, Val AUC: 0.7049, AP: 0.7669\n",
      "Epoch 050, Loss: 0.5617, Val AUC: 0.7040, AP: 0.7693\n",
      "Test AUC: 0.7052, Test AP: 0.7695\n"
     ]
    }
   ],
   "source": [
    "train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dc2319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1798b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htgnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
