{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "878b616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(\n",
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Implements the link prediction task on the FB15k237 datasets according to the\n",
    "`\"Modeling Relational Data with Graph Convolutional Networks\"\n",
    "<https://arxiv.org/abs/1703.06103>`_ paper.\n",
    "\n",
    "Caution: This script is executed in a full-batch fashion, and therefore needs\n",
    "to run on CPU (following the experimental setup in the official paper).\n",
    "\"\"\"\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.datasets import RelLinkPredDataset\n",
    "from torch_geometric.nn import GAE, RGCNConv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from utils.reorganized_preprocessing import get_edges_and_indices\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "path = osp.join(osp.dirname('data/RLPD'))\n",
    "dataset = RelLinkPredDataset(path, 'FB15k-237')\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "dataset = 'icews14'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d9383c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 544230], num_nodes=14541, edge_type=[544230], train_edge_index=[2, 272115], train_edge_type=[272115], valid_edge_index=[2, 17535], valid_edge_type=[17535], test_edge_index=[2, 20466], test_edge_type=[20466])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d1bf1",
   "metadata": {},
   "source": [
    "Transform the icews data so that it emulates the RealLinkPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7fff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist = pd.read_csv(f'../../../../data/raw/{dataset}/1-indexed/actor_actor.csv', encoding='utf-8', names=['userID','artistID', 'weight'],)\n",
    "user_friend = pd.read_csv(f'../../../../data/raw/{dataset}/1-indexed/actor_action.csv', encoding='utf-8', names=['userID', 'friendID'])\n",
    "artist_tag = pd.read_csv(f'../../../../data/raw/{dataset}/1-indexed/actor_sector.csv', encoding='utf-8', names=['artistID', 'tagID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ac401",
   "metadata": {},
   "source": [
    "For heterograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253377c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist = user_artist[['userID','artistID']]\n",
    "\n",
    "user_artist['artistID'] += user_artist['userID'].max()\n",
    "user_friend['friendID'] += user_artist['artistID'].max()\n",
    "artist_tag['artistID'] += user_artist['userID'].max()\n",
    "artist_tag['tagID'] += user_friend['friendID'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95a6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_edge_tensors(df, rel_id):\n",
    "    edge_index = torch.tensor(df.values.T, dtype=torch.long)  # shape [2, num_edges]\n",
    "    edge_type = torch.full((edge_index.size(1),), rel_id, dtype=torch.long)\n",
    "    return edge_index, edge_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a86998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "RELATION_DICT = {\n",
    "'actor_actor': 0,\n",
    "'actor_action': 1,\n",
    "'actor_sector': 2\n",
    "}\n",
    "\n",
    "edge_index_1, edge_type_1 = df_to_edge_tensors(user_artist, RELATION_DICT['actor_actor'])\n",
    "edge_index_2, edge_type_2 = df_to_edge_tensors(user_friend, RELATION_DICT['actor_action'])\n",
    "edge_index_3, edge_type_3 = df_to_edge_tensors(artist_tag, RELATION_DICT['actor_sector'])\n",
    "\n",
    "# Concatenate all edge indices and types\n",
    "edge_index = torch.cat([edge_index_1, edge_index_2, edge_index_3], dim=1)\n",
    "edge_type = torch.cat([edge_type_1, edge_type_2, edge_type_3], dim=0)\n",
    "\n",
    "# Infer number of nodes\n",
    "num_nodes = edge_index.max().item() + 1\n",
    "\n",
    "data = Data(\n",
    "    edge_index=edge_index,\n",
    "    edge_type=edge_type,\n",
    "    num_nodes=num_nodes\n",
    ")\n",
    "\n",
    "edge_array = edge_index.cpu().numpy().T  # Ensure it's on CPU before converting\n",
    "\n",
    "df_edges = pd.DataFrame(edge_array, columns=[\"head1\", \"head2\"])\n",
    "train_data, val_data, test_data, train_idx, val_idx, test_idx = get_edges_and_indices(user_artist, remove_fraction=1.0)\n",
    "\n",
    "data.train_edge_index = edge_index[:, train_idx]\n",
    "data.train_edge_type = edge_type[train_idx]\n",
    "\n",
    "data.valid_edge_index = edge_index[:, val_idx]\n",
    "data.valid_edge_type = edge_type[val_idx]\n",
    "\n",
    "data.test_edge_index = edge_index[:, test_idx]\n",
    "data.test_edge_type = edge_type[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6dd46c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 206337], edge_type=[206337], num_nodes=16577, train_edge_index=[2, 37472], train_edge_type=[37472], valid_edge_index=[2, 29033], valid_edge_type=[29033], test_edge_index=[2, 28994], test_edge_type=[28994])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e168d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_channels, num_relations):\n",
    "        super().__init__()\n",
    "        self.node_emb = Parameter(torch.empty(num_nodes, hidden_channels))\n",
    "        self.conv1 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=5)\n",
    "        self.conv2 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=5)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.node_emb)\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = self.node_emb\n",
    "        x = self.conv1(x, edge_index, edge_type).relu_()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DistMultDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_relations, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.rel_emb = Parameter(torch.empty(num_relations, hidden_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.rel_emb)\n",
    "\n",
    "    def forward(self, z, edge_index, edge_type):\n",
    "        z_src, z_dst = z[edge_index[0]], z[edge_index[1]]\n",
    "        rel = self.rel_emb[edge_type]\n",
    "        return torch.sum(z_src * rel * z_dst, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d62c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAE(\n",
    "    RGCNEncoder(data.num_nodes, 500, len(RELATION_DICT)*2),\n",
    "    DistMultDecoder(len(RELATION_DICT), 500),\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def negative_sampling(edge_index, num_nodes):\n",
    "    # Sample edges by corrupting either the subject or the object of each edge.\n",
    "    mask_1 = torch.rand(edge_index.size(1)) < 0.5\n",
    "    mask_2 = ~mask_1\n",
    "\n",
    "    neg_edge_index = edge_index.clone()\n",
    "    neg_edge_index[0, mask_1] = torch.randint(num_nodes, (mask_1.sum(), ),\n",
    "                                              device=neg_edge_index.device)\n",
    "    neg_edge_index[1, mask_2] = torch.randint(num_nodes, (mask_2.sum(), ),\n",
    "                                              device=neg_edge_index.device)\n",
    "    return neg_edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "780c66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_link_predictor(data_edge_, data):\n",
    "\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy()), average_precision_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_rank(ranks):\n",
    "    # fair ranking prediction as the average\n",
    "    # of optimistic and pessimistic ranking\n",
    "    true = ranks[0]\n",
    "    optimistic = (ranks > true).sum() + 1\n",
    "    pessimistic = (ranks >= true).sum()\n",
    "    return (optimistic + pessimistic).float() * 0.5\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_mrr(z, edge_index, edge_type):\n",
    "    ranks = []\n",
    "    for i in tqdm(range(edge_type.numel())):\n",
    "        (src, dst), rel = edge_index[:, i], edge_type[i]\n",
    "\n",
    "        # Try all nodes as tails, but delete true triplets:\n",
    "        tail_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "        for (heads, tails), types in [\n",
    "            (data.train_edge_index, data.train_edge_type),\n",
    "            (data.valid_edge_index, data.valid_edge_type),\n",
    "            (data.test_edge_index, data.test_edge_type),\n",
    "        ]:\n",
    "            tail_mask[tails[(heads == src) & (types == rel)]] = False\n",
    "\n",
    "        tail = torch.arange(data.num_nodes)[tail_mask]\n",
    "        tail = torch.cat([torch.tensor([dst]), tail])\n",
    "        head = torch.full_like(tail, fill_value=src)\n",
    "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
    "        eval_edge_type = torch.full_like(tail, fill_value=rel)\n",
    "\n",
    "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
    "        rank = compute_rank(out)\n",
    "        ranks.append(rank)\n",
    "\n",
    "        # Try all nodes as heads, but delete true triplets:\n",
    "        head_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "        for (heads, tails), types in [\n",
    "            (data.train_edge_index, data.train_edge_type),\n",
    "            (data.valid_edge_index, data.valid_edge_type),\n",
    "            (data.test_edge_index, data.test_edge_type),\n",
    "        ]:\n",
    "            head_mask[heads[(tails == dst) & (types == rel)]] = False\n",
    "\n",
    "        head = torch.arange(data.num_nodes)[head_mask]\n",
    "        head = torch.cat([torch.tensor([src]), head])\n",
    "        tail = torch.full_like(head, fill_value=dst)\n",
    "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
    "        eval_edge_type = torch.full_like(head, fill_value=rel)\n",
    "\n",
    "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
    "        rank = compute_rank(out)\n",
    "        ranks.append(rank)\n",
    "\n",
    "    return (1. / torch.tensor(ranks, dtype=torch.float)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd97fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    pos_out = model.decode(z, data.train_edge_index, data.train_edge_type)\n",
    "\n",
    "    neg_edge_index = negative_sampling(data.train_edge_index, data.num_nodes)\n",
    "    neg_out = model.decode(z, neg_edge_index, data.train_edge_type)\n",
    "\n",
    "    out = torch.cat([pos_out, neg_out])\n",
    "    gt = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
    "    cross_entropy_loss = F.binary_cross_entropy_with_logits(out, gt)\n",
    "    reg_loss = z.pow(2).mean() + model.decoder.rel_emb.pow(2).mean()\n",
    "    loss = cross_entropy_loss + 1e-2 * reg_loss\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    pred = out.sigmoid().detach().cpu().numpy()\n",
    "    labels = gt.detach().cpu().numpy()\n",
    "    auc = roc_auc_score(labels, pred)\n",
    "    ap = average_precision_score(labels, pred)\n",
    "\n",
    "\n",
    "    return float(loss), auc, ap\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    valid_mrr = compute_mrr(z, data.valid_edge_index, data.valid_edge_type)\n",
    "    test_mrr = compute_mrr(z, data.test_edge_index, data.test_edge_type)\n",
    "\n",
    "    return valid_mrr, test_mrr\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_auc_ap():\n",
    "    model.eval()\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    pos_out = model.decode(z, data.test_edge_index, data.test_edge_type)\n",
    "\n",
    "    neg_edge_index = negative_sampling(data.test_edge_index, data.num_nodes)\n",
    "    neg_out = model.decode(z, neg_edge_index, data.test_edge_type)\n",
    "\n",
    "    out = torch.cat([pos_out, neg_out])\n",
    "    gt = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
    "\n",
    "    pred = out.sigmoid().detach().cpu().numpy()\n",
    "    labels = gt.detach().cpu().numpy()\n",
    "    auc = roc_auc_score(labels, pred)\n",
    "    ap = average_precision_score(labels, pred)\n",
    "\n",
    "    print(f'Test evaluation: AUC : {auc:.6f}, AP : {ap:.6f}')\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "497c25a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00001, Loss: 0.6932, AUC : 0.504459, AP : 0.484171\n",
      "Epoch: 00002, Loss: 0.6925, AUC : 0.656592, AP : 0.577853\n",
      "Epoch: 00003, Loss: 0.6810, AUC : 0.839945, AP : 0.842165\n",
      "Epoch: 00004, Loss: 0.5951, AUC : 0.841805, AP : 0.829332\n",
      "Epoch: 00005, Loss: 0.5451, AUC : 0.895407, AP : 0.876474\n",
      "Epoch: 00006, Loss: 0.4002, AUC : 0.900100, AP : 0.879686\n",
      "Epoch: 00007, Loss: 0.4142, AUC : 0.899795, AP : 0.872289\n",
      "Epoch: 00008, Loss: 0.4609, AUC : 0.895369, AP : 0.857722\n",
      "Epoch: 00009, Loss: 0.3837, AUC : 0.906366, AP : 0.873253\n",
      "Epoch: 00010, Loss: 0.4040, AUC : 0.906375, AP : 0.872243\n",
      "Epoch: 00011, Loss: 0.3724, AUC : 0.906335, AP : 0.871334\n",
      "Epoch: 00012, Loss: 0.3811, AUC : 0.906476, AP : 0.873070\n",
      "Epoch: 00013, Loss: 0.3462, AUC : 0.915383, AP : 0.885476\n",
      "Epoch: 00014, Loss: 0.3812, AUC : 0.908394, AP : 0.874472\n",
      "Epoch: 00015, Loss: 0.3401, AUC : 0.921838, AP : 0.893324\n",
      "Epoch: 00016, Loss: 0.3509, AUC : 0.922443, AP : 0.895472\n",
      "Epoch: 00017, Loss: 0.3292, AUC : 0.925171, AP : 0.897176\n",
      "Epoch: 00018, Loss: 0.3409, AUC : 0.922984, AP : 0.890989\n",
      "Epoch: 00019, Loss: 0.3310, AUC : 0.924296, AP : 0.892568\n",
      "Epoch: 00020, Loss: 0.3225, AUC : 0.927675, AP : 0.901093\n",
      "Epoch: 00021, Loss: 0.3174, AUC : 0.932341, AP : 0.908459\n",
      "Epoch: 00022, Loss: 0.3124, AUC : 0.930705, AP : 0.904678\n",
      "Epoch: 00023, Loss: 0.3042, AUC : 0.932376, AP : 0.906796\n",
      "Epoch: 00024, Loss: 0.2971, AUC : 0.937384, AP : 0.914296\n",
      "Epoch: 00025, Loss: 0.2876, AUC : 0.940277, AP : 0.916881\n",
      "Epoch: 00026, Loss: 0.2870, AUC : 0.940411, AP : 0.918448\n",
      "Epoch: 00027, Loss: 0.2867, AUC : 0.940895, AP : 0.915230\n",
      "Epoch: 00028, Loss: 0.2737, AUC : 0.944748, AP : 0.922156\n",
      "Epoch: 00029, Loss: 0.2649, AUC : 0.946061, AP : 0.921264\n",
      "Epoch: 00030, Loss: 0.2637, AUC : 0.947778, AP : 0.923232\n",
      "Epoch: 00031, Loss: 0.2632, AUC : 0.946655, AP : 0.922223\n",
      "Epoch: 00032, Loss: 0.2538, AUC : 0.950218, AP : 0.926146\n",
      "Epoch: 00033, Loss: 0.2507, AUC : 0.951365, AP : 0.928879\n",
      "Epoch: 00034, Loss: 0.2534, AUC : 0.949939, AP : 0.927393\n",
      "Epoch: 00035, Loss: 0.2515, AUC : 0.951902, AP : 0.928232\n",
      "Epoch: 00036, Loss: 0.2465, AUC : 0.954184, AP : 0.934537\n",
      "Epoch: 00037, Loss: 0.2447, AUC : 0.957761, AP : 0.939485\n",
      "Epoch: 00038, Loss: 0.2340, AUC : 0.956912, AP : 0.938961\n",
      "Epoch: 00039, Loss: 0.2308, AUC : 0.957964, AP : 0.937241\n",
      "Epoch: 00040, Loss: 0.2250, AUC : 0.961234, AP : 0.944062\n",
      "Epoch: 00041, Loss: 0.2314, AUC : 0.958946, AP : 0.941848\n",
      "Epoch: 00042, Loss: 0.2500, AUC : 0.954562, AP : 0.927035\n",
      "Epoch: 00043, Loss: 0.2151, AUC : 0.963267, AP : 0.944861\n",
      "Epoch: 00044, Loss: 0.2392, AUC : 0.958500, AP : 0.943034\n",
      "Epoch: 00045, Loss: 0.2352, AUC : 0.964023, AP : 0.947673\n",
      "Epoch: 00046, Loss: 0.2524, AUC : 0.950748, AP : 0.925639\n",
      "Epoch: 00047, Loss: 0.2197, AUC : 0.963797, AP : 0.948477\n",
      "Epoch: 00048, Loss: 0.2315, AUC : 0.958795, AP : 0.939208\n",
      "Epoch: 00049, Loss: 0.2200, AUC : 0.964299, AP : 0.948683\n",
      "Epoch: 00050, Loss: 0.2057, AUC : 0.966527, AP : 0.948192\n",
      "Median time per epoch: 0.1195s\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "data.to('cuda')\n",
    "\n",
    "times = []\n",
    "for epoch in range(1, 51):\n",
    "    start = time.time()\n",
    "    loss, auc, ap = train()\n",
    "    print(f'Epoch: {epoch:05d}, Loss: {loss:.4f}, AUC : {auc:.6f}, AP : {ap:.6f}')\n",
    "    if (epoch % 100) == 0:\n",
    "        valid_mrr, test_mrr = test()\n",
    "        print(f'Val MRR: {valid_mrr:.4f}, Test MRR: {test_mrr:.4f}')\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ea6d584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test evaluation: AUC : 0.961456, AP : 0.954352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.961455667609898, 0.9543523083560672)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc_ap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c892e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htgnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
