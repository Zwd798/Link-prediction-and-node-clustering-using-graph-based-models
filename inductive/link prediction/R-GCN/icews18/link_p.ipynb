{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878b616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Implements the link prediction task on the FB15k237 datasets according to the\n",
    "`\"Modeling Relational Data with Graph Convolutional Networks\"\n",
    "<https://arxiv.org/abs/1703.06103>`_ paper.\n",
    "\n",
    "Caution: This script is executed in a full-batch fashion, and therefore needs\n",
    "to run on CPU (following the experimental setup in the official paper).\n",
    "\"\"\"\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.datasets import RelLinkPredDataset\n",
    "from torch_geometric.nn import GAE, RGCNConv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from utils.reorganized_preprocessing import get_edges_and_indices\n",
    "# Training on GPU causes OOM error\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "dataset = 'icews18'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7fff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist = pd.read_csv(f'../../../../data/raw/{dataset}/1-indexed/actor_actor.csv', encoding='utf-8', names=['userID','artistID', 'weight'],)\n",
    "user_friend = pd.read_csv(f'../../../../data/raw/{dataset}/1-indexed/actor_action.csv', encoding='utf-8', names=['userID', 'friendID'])\n",
    "artist_tag = pd.read_csv(f'../../../../data/raw/{dataset}/1-indexed/actor_sector.csv', encoding='utf-8', names=['artistID', 'tagID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ac401",
   "metadata": {},
   "source": [
    "For heterograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253377c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist = user_artist[['userID','artistID']]\n",
    "\n",
    "user_artist['artistID'] += user_artist['userID'].max()\n",
    "user_friend['friendID'] += user_artist['artistID'].max()\n",
    "artist_tag['artistID'] += user_artist['userID'].max()\n",
    "artist_tag['tagID'] += user_friend['friendID'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95a6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_edge_tensors(df, rel_id):\n",
    "    edge_index = torch.tensor(df.values.T, dtype=torch.long)  # shape [2, num_edges]\n",
    "    edge_type = torch.full((edge_index.size(1),), rel_id, dtype=torch.long)\n",
    "    return edge_index, edge_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a86998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nxz190009/miniconda3/envs/htgnn/lib/python3.10/site-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "RELATION_DICT = {\n",
    "'actor_actor': 0,\n",
    "'actor_action': 1,\n",
    "'actor_sector': 2\n",
    "}\n",
    "\n",
    "edge_index_1, edge_type_1 = df_to_edge_tensors(user_artist, RELATION_DICT['actor_actor'])\n",
    "edge_index_2, edge_type_2 = df_to_edge_tensors(user_friend, RELATION_DICT['actor_action'])\n",
    "edge_index_3, edge_type_3 = df_to_edge_tensors(artist_tag, RELATION_DICT['actor_sector'])\n",
    "\n",
    "# Concatenate all edge indices and types\n",
    "edge_index = torch.cat([edge_index_1, edge_index_2, edge_index_3], dim=1)\n",
    "edge_type = torch.cat([edge_type_1, edge_type_2, edge_type_3], dim=0)\n",
    "\n",
    "# Infer number of nodes\n",
    "num_nodes = edge_index.max().item() + 1\n",
    "\n",
    "data = Data(\n",
    "    edge_index=edge_index,\n",
    "    edge_type=edge_type,\n",
    "    num_nodes=num_nodes\n",
    ")\n",
    "\n",
    "edge_array = edge_index.cpu().numpy().T  # Ensure it's on CPU before converting\n",
    "\n",
    "df_edges = pd.DataFrame(edge_array, columns=[\"head1\", \"head2\"])\n",
    "train_data, val_data, test_data, train_idx, val_idx, test_idx = get_edges_and_indices(user_artist, remove_fraction=1.0)\n",
    "\n",
    "data.train_edge_index = edge_index[:, train_idx]\n",
    "data.train_edge_type = edge_type[train_idx]\n",
    "\n",
    "data.valid_edge_index = edge_index[:, val_idx]\n",
    "data.valid_edge_type = edge_type[val_idx]\n",
    "\n",
    "data.test_edge_index = edge_index[:, test_idx]\n",
    "data.test_edge_type = edge_type[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "389418da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 220530], edge_type=[220530], num_nodes=19140, train_edge_index=[2, 37335], train_edge_type=[37335], valid_edge_index=[2, 34073], valid_edge_type=[34073], test_edge_index=[2, 34538], test_edge_type=[34538])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5865b81",
   "metadata": {},
   "source": [
    "##### Works on CPU so this has been commented out\n",
    "\n",
    "Training on all these 220530 edges results in Out-of-Memory error and so reducing it to 200000 edges as ICEWS14 has around that number of edges and the training on ICEWS14 was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b7366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all edges and types\n",
    "# all_edge_index = torch.cat([\n",
    "#     data.train_edge_index, \n",
    "#     data.valid_edge_index, \n",
    "#     data.test_edge_index\n",
    "# ], dim=1)\n",
    "\n",
    "# all_edge_type = torch.cat([\n",
    "#     data.train_edge_type, \n",
    "#     data.valid_edge_type, \n",
    "#     data.test_edge_type\n",
    "# ])\n",
    "\n",
    "# # Total number of edges\n",
    "# num_total_edges = all_edge_index.size(1)\n",
    "\n",
    "# # Determine how many to keep\n",
    "# num_keep = 200000\n",
    "\n",
    "# # Random permutation of indices\n",
    "# perm = torch.randperm(num_total_edges)[:num_keep]\n",
    "\n",
    "# # Subset the edges\n",
    "# new_edge_index = all_edge_index[:, perm]\n",
    "# new_edge_type = all_edge_type[perm]\n",
    "\n",
    "# # Optional: If needed, re-split into train/val/test using some ratio\n",
    "# num_train = int(0.8 * num_keep)\n",
    "# num_val = int(0.1 * num_keep)\n",
    "# num_test = num_keep - num_train - num_val\n",
    "\n",
    "# train_edge_index = new_edge_index[:, :num_train]\n",
    "# train_edge_type = new_edge_type[:num_train]\n",
    "\n",
    "# valid_edge_index = new_edge_index[:, num_train:num_train + num_val]\n",
    "# valid_edge_type = new_edge_type[num_train:num_train + num_val]\n",
    "\n",
    "# test_edge_index = new_edge_index[:, num_train + num_val:]\n",
    "# test_edge_type = new_edge_type[num_train + num_val:]\n",
    "\n",
    "# # Update data object\n",
    "# data.train_edge_index = train_edge_index\n",
    "# data.train_edge_type = train_edge_type\n",
    "# data.valid_edge_index = valid_edge_index\n",
    "# data.valid_edge_type = valid_edge_type\n",
    "# data.test_edge_index = test_edge_index\n",
    "# data.test_edge_type = test_edge_type\n",
    "\n",
    "# data.edge_index = new_edge_index\n",
    "# data.edge_type = new_edge_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e168d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_channels, num_relations):\n",
    "        super().__init__()\n",
    "        self.node_emb = Parameter(torch.empty(num_nodes, hidden_channels))\n",
    "        self.conv1 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=5)\n",
    "        self.conv2 = RGCNConv(hidden_channels, hidden_channels, num_relations,\n",
    "                              num_blocks=5)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.node_emb)\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = self.node_emb\n",
    "        x = self.conv1(x, edge_index, edge_type).relu_()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DistMultDecoder(torch.nn.Module):\n",
    "    def __init__(self, num_relations, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.rel_emb = Parameter(torch.empty(num_relations, hidden_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.rel_emb)\n",
    "\n",
    "    def forward(self, z, edge_index, edge_type):\n",
    "        z_src, z_dst = z[edge_index[0]], z[edge_index[1]]\n",
    "        rel = self.rel_emb[edge_type]\n",
    "        return torch.sum(z_src * rel * z_dst, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d62c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAE(\n",
    "    RGCNEncoder(data.num_nodes, 500, len(RELATION_DICT)*2),\n",
    "    DistMultDecoder(len(RELATION_DICT), 500),\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def negative_sampling(edge_index, num_nodes):\n",
    "    # Sample edges by corrupting either the subject or the object of each edge.\n",
    "    mask_1 = torch.rand(edge_index.size(1)) < 0.5\n",
    "    mask_2 = ~mask_1\n",
    "\n",
    "    neg_edge_index = edge_index.clone()\n",
    "    neg_edge_index[0, mask_1] = torch.randint(num_nodes, (mask_1.sum(), ),\n",
    "                                              device=neg_edge_index.device)\n",
    "    neg_edge_index[1, mask_2] = torch.randint(num_nodes, (mask_2.sum(), ),\n",
    "                                              device=neg_edge_index.device)\n",
    "    return neg_edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "780c66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_link_predictor(data_edge_, data):\n",
    "\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy()), average_precision_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_rank(ranks):\n",
    "    # fair ranking prediction as the average\n",
    "    # of optimistic and pessimistic ranking\n",
    "    true = ranks[0]\n",
    "    optimistic = (ranks > true).sum() + 1\n",
    "    pessimistic = (ranks >= true).sum()\n",
    "    return (optimistic + pessimistic).float() * 0.5\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_mrr(z, edge_index, edge_type):\n",
    "    ranks = []\n",
    "    for i in tqdm(range(edge_type.numel())):\n",
    "        (src, dst), rel = edge_index[:, i], edge_type[i]\n",
    "\n",
    "        # Try all nodes as tails, but delete true triplets:\n",
    "        tail_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "        for (heads, tails), types in [\n",
    "            (data.train_edge_index, data.train_edge_type),\n",
    "            (data.valid_edge_index, data.valid_edge_type),\n",
    "            (data.test_edge_index, data.test_edge_type),\n",
    "        ]:\n",
    "            tail_mask[tails[(heads == src) & (types == rel)]] = False\n",
    "\n",
    "        tail = torch.arange(data.num_nodes)[tail_mask]\n",
    "        tail = torch.cat([torch.tensor([dst]), tail])\n",
    "        head = torch.full_like(tail, fill_value=src)\n",
    "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
    "        eval_edge_type = torch.full_like(tail, fill_value=rel)\n",
    "\n",
    "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
    "        rank = compute_rank(out)\n",
    "        ranks.append(rank)\n",
    "\n",
    "        # Try all nodes as heads, but delete true triplets:\n",
    "        head_mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "        for (heads, tails), types in [\n",
    "            (data.train_edge_index, data.train_edge_type),\n",
    "            (data.valid_edge_index, data.valid_edge_type),\n",
    "            (data.test_edge_index, data.test_edge_type),\n",
    "        ]:\n",
    "            head_mask[heads[(tails == dst) & (types == rel)]] = False\n",
    "\n",
    "        head = torch.arange(data.num_nodes)[head_mask]\n",
    "        head = torch.cat([torch.tensor([src]), head])\n",
    "        tail = torch.full_like(head, fill_value=dst)\n",
    "        eval_edge_index = torch.stack([head, tail], dim=0)\n",
    "        eval_edge_type = torch.full_like(head, fill_value=rel)\n",
    "\n",
    "        out = model.decode(z, eval_edge_index, eval_edge_type)\n",
    "        rank = compute_rank(out)\n",
    "        ranks.append(rank)\n",
    "\n",
    "    return (1. / torch.tensor(ranks, dtype=torch.float)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd97fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    pos_out = model.decode(z, data.train_edge_index, data.train_edge_type)\n",
    "\n",
    "    neg_edge_index = negative_sampling(data.train_edge_index, data.num_nodes)\n",
    "    neg_out = model.decode(z, neg_edge_index, data.train_edge_type)\n",
    "\n",
    "    out = torch.cat([pos_out, neg_out])\n",
    "    gt = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
    "    cross_entropy_loss = F.binary_cross_entropy_with_logits(out, gt)\n",
    "    reg_loss = z.pow(2).mean() + model.decoder.rel_emb.pow(2).mean()\n",
    "    loss = cross_entropy_loss + 1e-2 * reg_loss\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    pred = out.sigmoid().detach().cpu().numpy()\n",
    "    labels = gt.detach().cpu().numpy()\n",
    "    auc = roc_auc_score(labels, pred)\n",
    "    ap = average_precision_score(labels, pred)\n",
    "\n",
    "\n",
    "    return float(loss), auc, ap\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    valid_mrr = compute_mrr(z, data.valid_edge_index, data.valid_edge_type)\n",
    "    test_mrr = compute_mrr(z, data.test_edge_index, data.test_edge_type)\n",
    "\n",
    "    return valid_mrr, test_mrr\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_auc_ap():\n",
    "    model.eval()\n",
    "    z = model.encode(data.edge_index, data.edge_type)\n",
    "\n",
    "    pos_out = model.decode(z, data.test_edge_index, data.test_edge_type)\n",
    "\n",
    "    neg_edge_index = negative_sampling(data.test_edge_index, data.num_nodes)\n",
    "    neg_out = model.decode(z, neg_edge_index, data.test_edge_type)\n",
    "\n",
    "    out = torch.cat([pos_out, neg_out])\n",
    "    gt = torch.cat([torch.ones_like(pos_out), torch.zeros_like(neg_out)])\n",
    "\n",
    "    pred = out.sigmoid().detach().cpu().numpy()\n",
    "    labels = gt.detach().cpu().numpy()\n",
    "    auc = roc_auc_score(labels, pred)\n",
    "    ap = average_precision_score(labels, pred)\n",
    "\n",
    "    print(f'Test evaluation: AUC : {auc:.6f}, AP : {ap:.6f}')\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4315a0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 220530], edge_type=[220530], num_nodes=19140, train_edge_index=[2, 37335], train_edge_type=[37335], valid_edge_index=[2, 34073], valid_edge_type=[34073], test_edge_index=[2, 34538], test_edge_type=[34538])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "497c25a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00001, Loss: 0.6932, AUC : 0.476939, AP : 0.457054\n",
      "Epoch: 00002, Loss: 0.6920, AUC : 0.794015, AP : 0.736520\n",
      "Epoch: 00003, Loss: 0.6633, AUC : 0.866282, AP : 0.861678\n",
      "Epoch: 00004, Loss: 0.4594, AUC : 0.875053, AP : 0.865186\n",
      "Epoch: 00005, Loss: 1.5196, AUC : 0.888589, AP : 0.875506\n",
      "Epoch: 00006, Loss: 0.8747, AUC : 0.890732, AP : 0.878167\n",
      "Epoch: 00007, Loss: 0.3660, AUC : 0.920989, AP : 0.907271\n",
      "Epoch: 00008, Loss: 0.3582, AUC : 0.924834, AP : 0.901813\n",
      "Epoch: 00009, Loss: 0.3987, AUC : 0.916299, AP : 0.886787\n",
      "Epoch: 00010, Loss: 0.3865, AUC : 0.914703, AP : 0.879694\n",
      "Epoch: 00011, Loss: 0.3659, AUC : 0.912693, AP : 0.874301\n",
      "Epoch: 00012, Loss: 0.3662, AUC : 0.909614, AP : 0.870149\n",
      "Epoch: 00013, Loss: 0.3567, AUC : 0.919279, AP : 0.884269\n",
      "Epoch: 00014, Loss: 0.3259, AUC : 0.924241, AP : 0.888624\n",
      "Epoch: 00015, Loss: 0.3118, AUC : 0.929749, AP : 0.898343\n",
      "Epoch: 00016, Loss: 0.3193, AUC : 0.931942, AP : 0.906864\n",
      "Epoch: 00017, Loss: 0.3178, AUC : 0.931919, AP : 0.903720\n",
      "Epoch: 00018, Loss: 0.3219, AUC : 0.931375, AP : 0.910260\n",
      "Epoch: 00019, Loss: 0.3021, AUC : 0.935938, AP : 0.913684\n",
      "Epoch: 00020, Loss: 0.3082, AUC : 0.936335, AP : 0.911157\n",
      "Epoch: 00021, Loss: 0.3110, AUC : 0.937295, AP : 0.917158\n",
      "Epoch: 00022, Loss: 0.2907, AUC : 0.939686, AP : 0.918353\n",
      "Epoch: 00023, Loss: 0.3060, AUC : 0.937064, AP : 0.909924\n",
      "Epoch: 00024, Loss: 0.3071, AUC : 0.941846, AP : 0.922407\n",
      "Epoch: 00025, Loss: 0.2843, AUC : 0.943657, AP : 0.923161\n",
      "Epoch: 00026, Loss: 0.2969, AUC : 0.943246, AP : 0.917601\n",
      "Epoch: 00027, Loss: 0.2800, AUC : 0.944655, AP : 0.921637\n",
      "Epoch: 00028, Loss: 0.2889, AUC : 0.943882, AP : 0.923367\n",
      "Epoch: 00029, Loss: 0.2708, AUC : 0.947964, AP : 0.928748\n",
      "Epoch: 00030, Loss: 0.2754, AUC : 0.945674, AP : 0.921576\n",
      "Epoch: 00031, Loss: 0.2681, AUC : 0.947587, AP : 0.926177\n",
      "Epoch: 00032, Loss: 0.2693, AUC : 0.948052, AP : 0.927949\n",
      "Epoch: 00033, Loss: 0.2620, AUC : 0.950507, AP : 0.930941\n",
      "Epoch: 00034, Loss: 0.2564, AUC : 0.950989, AP : 0.929112\n",
      "Epoch: 00035, Loss: 0.2534, AUC : 0.951853, AP : 0.930413\n",
      "Epoch: 00036, Loss: 0.2539, AUC : 0.951926, AP : 0.932753\n",
      "Epoch: 00037, Loss: 0.2455, AUC : 0.954517, AP : 0.937374\n",
      "Epoch: 00038, Loss: 0.2470, AUC : 0.954825, AP : 0.936619\n",
      "Epoch: 00039, Loss: 0.2420, AUC : 0.954481, AP : 0.934129\n",
      "Epoch: 00040, Loss: 0.2369, AUC : 0.955615, AP : 0.935128\n",
      "Epoch: 00041, Loss: 0.2368, AUC : 0.955359, AP : 0.932901\n",
      "Epoch: 00042, Loss: 0.2330, AUC : 0.957913, AP : 0.939893\n",
      "Epoch: 00043, Loss: 0.2281, AUC : 0.958233, AP : 0.940686\n",
      "Epoch: 00044, Loss: 0.2249, AUC : 0.959073, AP : 0.941404\n",
      "Epoch: 00045, Loss: 0.2250, AUC : 0.958867, AP : 0.939914\n",
      "Epoch: 00046, Loss: 0.2225, AUC : 0.960140, AP : 0.942300\n",
      "Epoch: 00047, Loss: 0.2250, AUC : 0.960834, AP : 0.943089\n",
      "Epoch: 00048, Loss: 0.2234, AUC : 0.961572, AP : 0.943369\n",
      "Epoch: 00049, Loss: 0.2272, AUC : 0.963325, AP : 0.947052\n",
      "Epoch: 00050, Loss: 0.2107, AUC : 0.963913, AP : 0.947467\n",
      "Median time per epoch: 1.7380s\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "data.to(device)\n",
    "\n",
    "times = []\n",
    "for epoch in range(1, 51):\n",
    "    start = time.time()\n",
    "    loss, auc, ap = train()\n",
    "    print(f'Epoch: {epoch:05d}, Loss: {loss:.4f}, AUC : {auc:.6f}, AP : {ap:.6f}')\n",
    "    if (epoch % 100) == 0:\n",
    "        valid_mrr, test_mrr = test()\n",
    "        print(f'Val MRR: {valid_mrr:.4f}, Test MRR: {test_mrr:.4f}')\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ea6d584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test evaluation: AUC : 0.967276, AP : 0.965611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.967276469942104, 0.9656105442034884)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc_ap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c892e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htgnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
